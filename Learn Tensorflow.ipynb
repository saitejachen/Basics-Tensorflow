{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\sai\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "x=tf.Variable(5,name=\"x\")\n",
    "y=tf.Variable(10,name=\"y\")\n",
    "f=x*x+y*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n"
     ]
    }
   ],
   "source": [
    "sess=tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result=sess.run(f)\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result=f.eval()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n"
     ]
    }
   ],
   "source": [
    "init=tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result=f.eval()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init.run()\n",
    "result=f.eval()\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1=tf.Variable(1)\n",
    "\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "# LR using Normal Equation\n",
    "housing =fetch_california_housing()\n",
    "m,n=housing.data.shape\n",
    "housing_data_plus_bias=np.c_[np.ones((m,1)),housing.data]\n",
    "\n",
    "X=tf.constant(housing_data_plus_bias,dtype=tf.float32,name=\"X\")\n",
    "y=tf.constant(housing.target.reshape(-1,1),dtype=tf.float32,name=\"y\")\n",
    "XT=tf.transpose(X)\n",
    "theta=tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT,X)),XT),y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_val=theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.7171074e+01]\n",
      " [ 4.3633682e-01]\n",
      " [ 9.3871783e-03]\n",
      " [-1.0717344e-01]\n",
      " [ 6.4540231e-01]\n",
      " [-4.1238391e-06]\n",
      " [-3.7809242e-03]\n",
      " [-4.2373490e-01]\n",
      " [-4.3720812e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(theta_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 MSE= 5.653334\n",
      "Epoch  100 MSE= 1.3626162\n",
      "Epoch  200 MSE= 0.74454606\n",
      "Epoch  300 MSE= 0.6405453\n",
      "Epoch  400 MSE= 0.6138457\n",
      "Epoch  500 MSE= 0.6007086\n",
      "Epoch  600 MSE= 0.5910408\n",
      "Epoch  700 MSE= 0.5829661\n",
      "Epoch  800 MSE= 0.57600015\n",
      "Epoch  900 MSE= 0.5699361\n",
      "[[ 2.068468  ]\n",
      " [ 0.9218707 ]\n",
      " [ 0.1887558 ]\n",
      " [-0.34211177]\n",
      " [ 0.32638732]\n",
      " [ 0.02019763]\n",
      " [-0.04730525]\n",
      " [-0.30816892]\n",
      " [-0.28487548]]\n"
     ]
    }
   ],
   "source": [
    "# LR using GD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaled_housing_data=scaler.fit_transform(housing.data)\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "scaled_housing_data_plus_bias=np.c_[np.ones((m,1)),scaled_housing_data]\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias,dtype=tf.float32,name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1),dtype=tf.float32,name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1,1),name=\"theta\")\n",
    "y_pred = tf.matmul(X,theta,name=\"pred\")\n",
    "error = y_pred-y\n",
    "mse = tf.reduce_mean(tf.square(error),name=\"mse\")\n",
    "# Using Manual Gradient\n",
    "grad= 1/m * tf.matmul(tf.transpose(X),error)\n",
    "training_op = tf.assign(theta,theta- learning_rate*grad)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range (n_epochs):\n",
    "        if epoch%100 == 0:\n",
    "            print(\"Epoch \",epoch , \"MSE=\",mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta=theta.eval()\n",
    "\n",
    "    \n",
    "print(best_theta)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 MSE= 9.161083\n",
      "Epoch  100 MSE= 0.70065236\n",
      "Epoch  200 MSE= 0.550026\n",
      "Epoch  300 MSE= 0.54201794\n",
      "Epoch  400 MSE= 0.538022\n",
      "Epoch  500 MSE= 0.5350278\n",
      "Epoch  600 MSE= 0.5327325\n",
      "Epoch  700 MSE= 0.53096217\n",
      "Epoch  800 MSE= 0.52958953\n",
      "Epoch  900 MSE= 0.5285197\n",
      "[[ 2.0685525e+00]\n",
      " [ 8.6836165e-01]\n",
      " [ 1.3765329e-01]\n",
      " [-3.1695876e-01]\n",
      " [ 3.3865386e-01]\n",
      " [ 1.8705809e-03]\n",
      " [-4.1751351e-02]\n",
      " [-7.2572112e-01]\n",
      " [-6.9983274e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Using autodiff\n",
    "\n",
    "grad= tf.gradients(mse,[theta])[0]\n",
    "training_op = tf.assign(theta,theta- learning_rate*grad)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range (n_epochs):\n",
    "        if epoch%100 == 0:\n",
    "            print(\"Epoch \",epoch , \"MSE=\",mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta=theta.eval()\n",
    "\n",
    "    \n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 MSE= 7.5210333\n",
      "Epoch  100 MSE= 0.9029567\n",
      "Epoch  200 MSE= 0.71204966\n",
      "Epoch  300 MSE= 0.65774345\n",
      "Epoch  400 MSE= 0.6205691\n",
      "Epoch  500 MSE= 0.5938169\n",
      "Epoch  600 MSE= 0.5745118\n",
      "Epoch  700 MSE= 0.5605766\n",
      "Epoch  800 MSE= 0.5505162\n",
      "Epoch  900 MSE= 0.5432523\n",
      "[[ 2.0685525 ]\n",
      " [ 0.7438939 ]\n",
      " [ 0.14852081]\n",
      " [-0.01782127]\n",
      " [ 0.06315883]\n",
      " [ 0.00743982]\n",
      " [-0.04001681]\n",
      " [-0.76338315]\n",
      " [-0.7199136 ]]\n"
     ]
    }
   ],
   "source": [
    "# Using Optimizers\n",
    "\n",
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op=optimizer.minimize(mse)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range (n_epochs):\n",
    "        if epoch%100 == 0:\n",
    "            print(\"Epoch \",epoch , \"MSE=\",mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta=theta.eval()\n",
    "\n",
    "    \n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6. 7. 8.]]\n",
      "[[ 9. 10. 11.]\n",
      " [12. 13. 14.]]\n"
     ]
    }
   ],
   "source": [
    "# Placeholder\n",
    "\n",
    "A=tf.placeholder(tf.float32,shape=(None,3))\n",
    "B=A+5\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    B_val_1=B.eval(feed_dict={A: [[1,2,3]]})\n",
    "    B_val_2=B.eval(feed_dict={A: [[4,5,6],[7,8,9]]})\n",
    "print(B_val_1)\n",
    "print(B_val_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "Epoch :  0\n",
      "Epoch :  1\n",
      "Epoch :  2\n",
      "Epoch :  3\n",
      "Epoch :  4\n",
      "Epoch :  5\n",
      "Epoch :  6\n",
      "Epoch :  7\n",
      "Epoch :  8\n",
      "Epoch :  9\n",
      "Epoch :  10\n",
      "Epoch :  11\n",
      "Epoch :  12\n",
      "Epoch :  13\n",
      "Epoch :  14\n",
      "Epoch :  15\n",
      "Epoch :  16\n",
      "Epoch :  17\n",
      "Epoch :  18\n",
      "Epoch :  19\n",
      "Epoch :  20\n",
      "3.8434768\n",
      "Epoch :  21\n",
      "Epoch :  22\n",
      "Epoch :  23\n",
      "Epoch :  24\n",
      "Epoch :  25\n",
      "Epoch :  26\n",
      "Epoch :  27\n",
      "Epoch :  28\n",
      "Epoch :  29\n",
      "Epoch :  30\n",
      "Epoch :  31\n",
      "Epoch :  32\n",
      "Epoch :  33\n",
      "Epoch :  34\n",
      "Epoch :  35\n",
      "Epoch :  36\n",
      "Epoch :  37\n",
      "Epoch :  38\n",
      "Epoch :  39\n",
      "Epoch :  40\n",
      "Epoch :  41\n",
      "1.9431906\n",
      "Epoch :  42\n",
      "Epoch :  43\n",
      "Epoch :  44\n",
      "Epoch :  45\n",
      "Epoch :  46\n",
      "Epoch :  47\n",
      "Epoch :  48\n",
      "Epoch :  49\n",
      "Epoch :  50\n",
      "Epoch :  51\n",
      "Epoch :  52\n",
      "Epoch :  53\n",
      "Epoch :  54\n",
      "Epoch :  55\n",
      "Epoch :  56\n",
      "Epoch :  57\n",
      "Epoch :  58\n",
      "Epoch :  59\n",
      "Epoch :  60\n",
      "Epoch :  61\n",
      "Epoch :  62\n",
      "1.1983553\n",
      "[[ 1.4915392 ]\n",
      " [ 0.7989615 ]\n",
      " [-0.21953104]\n",
      " [-0.70236874]\n",
      " [ 0.60696596]\n",
      " [-0.299409  ]\n",
      " [ 0.02140428]\n",
      " [-0.00430318]\n",
      " [-0.11726115]]\n"
     ]
    }
   ],
   "source": [
    "X=tf.placeholder(tf.float32,shape=(None,n+1),name=\"X\")\n",
    "y=tf.placeholder(tf.float32,shape=(None,1),name=\"y\")\n",
    "\n",
    "batch_size=1000;\n",
    "n_epochs=3\n",
    "n_batches=int(np.ceil(m/batch_size))\n",
    "init=tf.global_variables_initializer()\n",
    "print(n_batches)\n",
    "def fetch_batch (epoch ,batch_index,batch_size):\n",
    "    X_batch=tf.constant(scaled_housing_data_plus_bias[batch_index*batch_size : (batch_index+1)*batch_size],dtype=tf.float32,name=\"X\")\n",
    "    y_batch=tf.constant(housing.target.reshape(-1,1),dtype=tf.float32,name=\"y\")\n",
    "    return X_batch,y_batch\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch,y_batch=fetch_batch(epoch,batch_index,batch_size)\n",
    "            X_batch=X_batch.eval()\n",
    "            y_batch=y_batch.eval()\n",
    "            sess.run(training_op,feed_dict={X:X_batch,y:y_batch})\n",
    "            print(\"Epoch : \",epoch*n_batches+batch_index)\n",
    "        print(mse.eval())\n",
    "    best_theta=theta.eval()\n",
    "\n",
    "print(best_theta)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now=datetime.utcnow().strftime(\"%y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir=\"{}/run-{}/\".format(root_logdir,now)\n",
    "\n",
    "mse_summary = tf.summary.scalar('MSE',mse)\n",
    "file_writer = tf.summary.FileWriter(logdir,tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "8\n",
      "8\n",
      "10\n",
      "10\n",
      "12\n",
      "12\n",
      "14\n",
      "14\n",
      "16\n",
      "16\n",
      "18\n",
      "18\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "n_epochs=1\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch,y_batch=fetch_batch(epoch,batch_index,batch_size)\n",
    "            X_batch=X_batch.eval()\n",
    "            y_batch=y_batch.eval()\n",
    "            if batch_index % 2 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X:X_batch,y:y_batch})\n",
    "                step=epoch*n_batches+batch_index\n",
    "                file_writer.add_summary(summary_str,step)\n",
    "            sess.run(training_op,feed_dict={X:X_batch,y:y_batch})\n",
    "            print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Sai\\\\Desktop\\\\Jupyter Notebooks'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
